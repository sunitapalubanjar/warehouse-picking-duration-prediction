---
title: "Data_cleaning"
output: html_document
date: "2026-02-22"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1. Understand the Dataset
## 1.1 Load Dataset and data overview
In this section, I load the raw logistics picking dataset and perform a basic inspection to understand its structure. I check the number of observations and features, the data types, and a statistical summary. This step is essential for identifying potential issues such as missing values, inconsistent formats, or parsing errors that may need to be addressed before further analysis.

```{r}
# Load required packages


library(readr)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(dplyr)


# Read dataset

logistics_picking_data <- read_delim("../data/anonymized_logistics_picking_data.csv", delim = ";")



# Summary statistics
summary(logistics_picking_data)
```



The dataset contains 217,963 rows and 18 variables, including characters, numerics, dates, and datetimes. Some fields like volume were parsed as characters due to comma formatting. Variables with only NA values (e.g., wm_srsrc, wm_qdocno) may be excluded.




# 2. Data Cleaning
## 2.1 Dataset Dimensions and Identifier Cardinality

```{r}

# Count unique values
length(unique(logistics_picking_data$collli_id))      # Unique colli_id
length(unique(logistics_picking_data$product_id))    # Unique product_id
length(unique(logistics_picking_data$picker)) #unique pickers


```
There are 8,369 unique order IDs (colli_id), 185 distinct products, and 37 pickers. These counts confirm that the dataset is diverse and includes meaningful variation in both product types and worker identities. However, the high cardinality of colli_id and product_id suggests they may not be ideal as direct predictors in modeling, aligning with the decision to exclude them.

## 2.2 Creating New Variables and Data Formatting
In this section, I prepared the dataset for analysis by engineering new features and correcting data formatting issues. Specifically, I extracted location components, calculated task duration, standardized the volume variable, and created weekday labels for temporal analysis. I also converted character columns to factors to ensure they are treated correctly in modeling. To verify that these steps were successful, I reviewed sample values and summary statistics of the updated dataset.


```{r}

# Get row and ID from location string
logistics_picking_data <- logistics_picking_data %>%
  mutate(
    location_row = as.numeric(str_sub(location, 4, 5)),
    location_id = as.numeric(str_sub(location, 7, 9))
  )

# Calculate picking duration in seconds
logistics_picking_data <- logistics_picking_data %>%
  mutate(picking_duration_sec = as.numeric(difftime(finish_time, start_time, units = "secs")))

# Fix comma in volume and convert to number
logistics_picking_data <- logistics_picking_data %>%
  mutate(volume = as.numeric(gsub(",", ".", volume)))

# Set English weekday names (for Windows)
Sys.setlocale("LC_TIME", "English_United States.1252")

```




```{r}

# Create weekday name from calendar day
logistics_picking_data <- logistics_picking_data %>%
  mutate(
    calday_date = ymd(calday),
    weekday_name = weekdays(calday_date)
  )

# Convert all character columns to factors
for (i in 1:ncol(logistics_picking_data)) {
  if (is.character(logistics_picking_data[[i]])) {
    logistics_picking_data[[i]] <- factor(logistics_picking_data[[i]])
  }
}


```


```{r}
# Check selected variables after transformation

logistics_picking_data %>%
  select(start_time, finish_time, picking_duration_sec, volume, weekday_name) %>%
  head(5)


```
```{r}
# Review summary statistics of full dataset
summary(logistics_picking_data)
```
The output confirms that the newly created variables such as picking_duration_sec, location_row, and weekday_name were correctly generated. The volume variable was successfully converted to numeric format. Summary statistics further indicate that the dataset is structurally sound and ready for exploratory data analysis and modeling.

```{r}
# save clean data
saveRDS(logistics_picking_data, "../data/clean_logistics_picking_data.rds")

```